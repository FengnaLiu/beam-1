<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="../github.css">
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<style type="text/css">
  .head { 
    border-left:5px solid #00f;
    padding:3px 0 3px 10px;
    font-weight: bold;
  }
  .lhead { 
    border-left:5px solid #00f;
    padding:3px 0 3px 10px;
    font-size:14pt;
    font-weight: bold;
  }
</style>
<p><a href="../index.html">topへ</a></p>
<h1 id="overview">Overview</h1>
<h2 id="beamによるデータ処理"><span class="head">Beamによるデータ処理</span></h2>
<p>Beamを使ったプログラミング、および実行の際に、ユーザが決めるべきことは</p>
<ol type="1">
<li>Beamプログラミング</li>
</ol>
<ul>
<li>実行時オプションの定義</li>
<li>Inputの定義</li>
<li>行う変換処理の定義</li>
<li>Outputの定義</li>
</ul>
<ol start="2" type="1">
<li>Pipelineの実行</li>
</ol>
<ul>
<li>実行環境（Runner）の指定</li>
<li>実行時オプションの指定</li>
</ul>
<p>Beamが動く環境はたくさんある。ローカルだったらDirectRunner、 DataflowだったらDataflowRunnerみたいな。詳しくは<a href="https://beam.apache.org/documentation/runners/capability-matrix/">こちら</a>を参照。</p>
<h2 id="beamで現れる概念"><span class="head">beamで現れる概念</span></h2>
<p>Beamには特有の用語がいくつかあります。</p>
<ul>
<li><p><code>Pipeline</code><br />
データ処理の最初から最後まで。全体的な何か。 実行時オプションは<code>Pipeline</code>を作る時に指定する。</p></li>
<li><code>PCollection</code><br />
<code>Pipeline</code>で捌くdatasetの単位。<code>PCollection</code>のソース（データの入力元）はboundでもunboundでもいい。</li>
<li>bound<br />
ファイルみたいに、決まったサイズを持つもの。</li>
<li><p>unbound<br />
Twitterみたいにデータに終わりのないもの。</p></li>
</ul>
<p>通常は外部ソースからdataを読み込むけど、unit testや練習のために、in-memoryに記述してもok。</p>
<ul>
<li><p><code>PTransform</code><br />
変換処理のこと。<code>PCollection</code>をinputとして受け取り、処理を加えた<code>PCollection</code>をoutputとして返す。input, outputともに複数の<code>PCollection</code>を取れる。<br />
Beam SDKで提供される<code>PTransform</code>を使ってもいいし、user定義関数を作ってもいい。</p></li>
<li><p>I/O Transform<br />
Beamでは様々な入出力先を指定できる。Datastore, BigQuery, Cloud Storage, Amazon S3, ... etc.</p></li>
</ul>
<h2 id="codingの流れ"><span class="head">Codingの流れ</span></h2>
<p><strong>1. Pipelineの作成</strong><br />
実行時のオプション（入出力先とか）、Runnerの指定はこの段階で。ただ、Runnerを指定するためにコードを返る必要は特に無い、はず。</p>
<p><strong>2. PCollectionの初期値作成</strong><br />
I/O Transformを使って外部から読むか、in-memoryのdataを使うかのどちらか。</p>
<p><strong>3. PTransformの適用</strong><br />
できることを大雑把に触れておくと、</p>
<ul>
<li>データの変換、整形</li>
<li>フィルター</li>
<li>グループ化</li>
<li>解析</li>
<li><code>PCollection</code>内の要素を調べる</li>
</ul>
<p>とか。<code>PTransform</code>では、入力の<code>PCollection</code>は変換されず、新たな<code>PCollection</code>を出力として返すため、変換前の<code>PCollection</code>は再利用ができる。</p>
<p><strong>4. I/OTransformで、外部への出力</strong><br />
ローカルファイルとか、BigQueryのtableに保存できる。</p>
<p><strong>5. Pipelineの実行</strong><br />
上記の一連の処理の流れを作り終えたら、<code>pipeline</code>を実行してくれ！っていうメソッドの呼び出してcodingは終わり。<br />
処理の一連の流れはgraphっていう。こんな感じでgraphに分岐があってもokです。 <img src="https://cloud.google.com/dataflow/images/monitoring-side-input-write.png" title="graph" alt="graph" /></p>
<p>Beamの動作詳細としては、まずpipelineのgraphを作成する。これは、後に触れる（かも）テンプレートの作成においてもそう。 もしテンプレート作成でなくてpipelineを実行させる場合は、作成されたgraphをもとに実際の処理が行われる。<br />
BeamでのPipeline処理は<strong>非同期</strong>処理です。並行分散処理なので、特定の処理は一回だけ行いたい、とか行う処理の順番を指定したい、とかは苦手なはずです。</p>
</body>
</html>
